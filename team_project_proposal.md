# *AudioAR* Team Project Proposal v02


[Our Hub : github/AudioAR](https://github.com/AudioAR)

[Our Document : github/AudioAR/doc](https://github.com/AudioAR/doc/)


### 项目简介

如何在VR中提供真实的、能够精确辨别位置的音频是近年的技术热点。VR业界许多公司都开发了相应的工具，包括Oculus在自身的Oculus Rift中集成了空间声场功能，Google在其GVR SDK中包含了Spatial Audio，专门提供立体声音合成功能。我们的设想是通过GPS和惯性定位等定位技术，将室内和室外的环境和虚拟空间重叠，通过追踪用户头部的运动，合成逼真的音频流，构建一个简单的AR音频平台。用户可以通过物理上的移动，使用听觉观察虚拟世界。

### 基本信息

队伍名称：**RecT**
项目名称：**AudioAR**

| 姓名|学号|邮箱|手机|
| -------- | :-----: | :----: | :-----: |
|丁雨晨|516030910498|mrdhf1997@163.com|15005669975|
|李东岳|516030910502|lidongyue@sjtu.edu.cn|13262511073|
|李杰宇|516030910503|ljy9792@hotmail.com|18217532938|
|罗铨|516030910506|574166505@qq.com|18802535879|
|__刘知峻(PM)__|516030910504|mr.jimmy@foxmail.com|13262655319|
|缪本杰|516030910509|925332765@qq.com|13166301938|

### 预想用户

希望体验虚拟音频与建造音频世界的玩家；
有兴趣进行AR音频展示的个人或企业，如活动主办方等；

### 用户界面

TODO("UI mock-up is to be updated")
用户界面基于 Android，主要包括这些功能，从核心到最不重要：

- 游戏界面，进行AR体验
- 地图View，位置、方向、高度显示和地图
- 传感器连接与校准界面
- 资源界面，离线与在线音频资源库
- 构造界面，在某地理位置放置、删除音频源
- 登陆View，Sign in / Sign up
- 个人信息设置界面

### 技术原理与功能设计
应用基于android平台，应用的技术从最底层到最顶层有；

- 定位与头部追踪
    * 基于无线惯性传感器或者android手机自身惯性传感器进行的头部运动定位
    * 基于GPS、惯性导航和步态识别融合的室外头部定位
    * 基于磁场、Wifi、蓝牙、惯性导航和步态识别融合的室内头部定位
        + 室内地图
        + 楼层识别
    * 基于以上技术设施构建的室内外连续定位

- 立体声场仿真
    * 基于音频流处理的android音频实时处理
        + Android 音频回放
        + Android 多线程与多进程
    * 基于 HRTF 的立体声场还原

- 服务器端
    * 基于 python 与 flask 构建的web服务作为整个应用的后台，实现用户登陆与资源上传下载等
    * MySQL 作为后端数据库技术
    * 简单起见，接口采用 RESTful API

- 用户界面与数据可视化
    * 基于 Android UI 实现用户界面
        + 基于 MVVM 开发UI界面
        + 完全基于 Fragment
    * 基于 web 或者 python 等实现后台数据处理和调试

### 技术可行性分析

首先应当说明，上面所列出的技术方案基于最理想状况的假设。项目包含四个技术层面：头部追踪、立体声场生成、用户界面、服务器端，四个不同的部分分别面临不同程度的技术风险，其中以前两项风险最高。对于相应的技术风险，我们有如下的解决方案：

- 关于头部追踪：

简单的不涉及躯体移动的头部转动跟踪实现难度低。组内已经购买了多轴传感器，用于实现头部定位。其精度和灵敏度可以达到要求；该产品说明书上也有详细的使用接口。

而涉及到室内外融合的定位难度较高。在技术原理部分提到，我们设计了通过(a)GPS与惯性导航(b)步态识别(c)磁场、Wifi、蓝牙 等方案进行实现，并期望把这些方案融合。其中，(a)是工业上已经比较成熟的解决方案，在项目中我们可以尽快实现；而(b)和(c)相对研究较少的，而比较精确和综合的方案，相关的研究大多还停留在理论层面，在项目时间有空余的情况下我们将进行尝试。我们将对定位部分进行封装，将逻辑与应用层进行解耦，方便技术迭代。

如果开发失败，作为保底方案，我们将利用模拟的位置信号进行开发。

关于硬件设备的配备问题，前面已经提到，组内已经购买了用于追踪传感器；同时手机自带的传感器经过封装也可以用于开发。

- 关于立体声场生成：

我们发现，Google VR中的音频处理库GVR Resonance Audio已经实现了立体声场的生成，且近日Google 已将该库开源。我们选择直接调用 GVR SDK 进行开发，并将对声音处理部分进行封装，方便技术进一步迭代。

由于立体声场需要根据用户的头部及方位移动行为进行实时计算，性能上的问题可能会随之出现：手机性能有限，是否能够支持实时计算生成立体声场的计算量？ 目前，业界现有的技术方案已经涉及到各种性能优化，其中包括Google采用的将音频统一投影之后进行一次HRTF计算的方法等，已经一定程度的解决了这一问题。另外，在同一个场景中会出现的音频数量有限，目前我们认为性能问题可以被解决。如果这一问题真的出现，我们也可以适当降低用户体验来弥补性能缺陷，以此来作为最底线的解决方案。

- 用户界面与服务器端逻辑：

组内多名同学有Android开发经验和web开发经验，熟悉python语言和Java语言。预计用户界面和后台的设计和实现不会造成太大问题。

### 复用代码

- GVR android 开发包
- 百度地图 开发包
